{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RowwiseDataset(Dataset):\n",
    "    def __init__(self, X_folder, y_attack_folder):\n",
    "        self.X_data = pd.concat(\n",
    "            [pd.read_parquet(f) for f in sorted(glob.glob(os.path.join(X_folder, \"*.parquet\")))]\n",
    "        ).values\n",
    "        self.y_attack_data = pd.concat(\n",
    "            [pd.read_parquet(f)[\"Attack\"] for f in sorted(glob.glob(os.path.join(y_attack_folder, \"*.parquet\")))]\n",
    "        ).values\n",
    "        assert len(self.X_data) == len(self.y_attack_data), \\\n",
    "            \"Mismatched row counts between features and labels.\"\n",
    "        assert self.y_attack_data.ndim == 1, \"Target data should be 1D after column selection.\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.X_data[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.y_attack_data[idx], dtype=torch.float32),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_folder = \"/kaggle/input/nf-ton-iot-v2-cleaned-scaled-split/rmv_outlier_std_801010/X_train\"\n",
    "y_train_attack_folder = \"/kaggle/input/nf-ton-iot-v2-cleaned-scaled-split/rmv_outlier_std_801010/y_train_attack\"\n",
    "\n",
    "X_valid_folder = \"/kaggle/input/nf-ton-iot-v2-cleaned-scaled-split/rmv_outlier_std_801010/X_valid\"\n",
    "y_valid_attack_folder = \"/kaggle/input/nf-ton-iot-v2-cleaned-scaled-split/rmv_outlier_std_801010/y_valid_attack\"\n",
    "\n",
    "X_test_folder = \"/kaggle/input/nf-ton-iot-v2-cleaned-scaled-split/rmv_outlier_std_801010/X_test\"\n",
    "y_test_attack_folder = \"/kaggle/input/nf-ton-iot-v2-cleaned-scaled-split/rmv_outlier_std_801010/y_test_attack\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = RowwiseDataset(X_train_folder, y_train_attack_folder)\n",
    "valid_dataset = RowwiseDataset(X_valid_folder, y_valid_attack_folder)\n",
    "test_dataset = RowwiseDataset(X_test_folder, y_test_attack_folder)\n",
    "\n",
    "X_train, y_train_attack = train_dataset.X_data, train_dataset.y_attack_data\n",
    "X_valid, y_valid_attack = valid_dataset.X_data, valid_dataset.y_attack_data\n",
    "X_test, y_test_attack = test_dataset.X_data, test_dataset.y_attack_data\n",
    "\n",
    "y_train = y_train_attack\n",
    "y_valid = y_valid_attack\n",
    "y_test = y_test_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}, y_valid shape: {y_valid.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, cls_num_list, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "        if alpha is None:\n",
    "            self.alpha = torch.ones(len(cls_num_list))\n",
    "        else:\n",
    "            self.alpha = torch.tensor(alpha)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        probs = F.softmax(inputs, dim=1)\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=inputs.size(1)).float()\n",
    "\n",
    "        log_probs = torch.log(probs + 1e-12)\n",
    "        focal_weight = (1 - probs).pow(self.gamma)\n",
    "\n",
    "        loss = -self.alpha.to(inputs.device) * focal_weight * targets_one_hot * log_probs\n",
    "        loss = loss.sum(dim=1)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cls_num_list = [4357259, 2943073, 1001429, 961486, 480101, 152251, 125024, 4149, 427, 109]\n",
    "alpha = [1 / x for x in cls_num_list]\n",
    "focal_loss = FocalLoss(cls_num_list=cls_num_list, gamma=2.0, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sizes = [8, 16, 32, 64]\n",
    "results = []\n",
    "\n",
    "for size in sizes:\n",
    "    print(f\"Training TabNet with n_a=n_d={size}\")\n",
    "\n",
    "    clf = TabNetClassifier(\n",
    "        device_name='cuda',\n",
    "        n_d=size,\n",
    "        n_a=size,\n",
    "        lambda_sparse=0,\n",
    "        mask_type='entmax',\n",
    "        optimizer_params=dict(lr=1e-2, weight_decay=1e-5),\n",
    "        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        scheduler_params={\n",
    "            \"mode\": \"min\",\n",
    "            \"factor\": 0.5,\n",
    "            \"patience\": 10,\n",
    "            \"min_lr\": 1e-5,\n",
    "        },\n",
    "        verbose=1,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    clf.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_metric=[\"balanced_accuracy\", \"accuracy\"],\n",
    "        max_epochs=100000,\n",
    "        patience=30,\n",
    "        batch_size=1024 * 10,\n",
    "        virtual_batch_size=128 * 10,\n",
    "        loss_fn=focal_loss,\n",
    "        compute_importance=False,\n",
    "    )\n",
    "\n",
    "    model_path = f\"focal_loss_tabnet_model_size_{size}.zip\"\n",
    "    clf.save_model(model_path)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    predictions_path = f\"focal_loss_y_pred_size_{size}.csv\"\n",
    "    pd.DataFrame(y_pred, columns=[\"y_pred\"]).to_csv(predictions_path, index=False)\n",
    "\n",
    "    results.append({\n",
    "        \"size\": size,\n",
    "        \"accuracy\": acc,\n",
    "        \"f1_score\": f1,\n",
    "        \"model_path\": model_path,\n",
    "        \"predictions_path\": predictions_path,\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"focal_loss_results_summary.csv\", index=False)\n",
    "\n",
    "print(\"Tuning completed. Models, predictions, and results have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6302222,
     "sourceId": 10199111,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
